{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage\n",
    "\n",
    "from fmm_data_generator_3d import create_dataset\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.chdir('/home/sharath/Documents/Existensial Robotics Lab/Planning_Operator/3D_Experiments/dataset')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 80, 80, 80)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.ndimage\n",
    "\n",
    "# Load the 3D occupancy maps from a file\n",
    "maps = np.load(\"gibsonenv121-hres/occupancymap.npy\")\n",
    "\n",
    "# Indices of maps to exclude\n",
    "exclude_indices = {0, 2, 9, 17, 23, 25}\n",
    "\n",
    "# Create an empty list to store the scaled maps\n",
    "scaled_maps_list = []\n",
    "\n",
    "# Compute the scale factor for resizing (from 121 to 80)\n",
    "scale_factor = 80 / 121\n",
    "\n",
    "# Loop through each map, rescale, and store it if the index is not excluded\n",
    "for i, map in enumerate(maps):\n",
    "    if i not in exclude_indices:\n",
    "        # Rescale the current 3D occupancy map\n",
    "        scaled_map = scipy.ndimage.zoom(map, zoom=scale_factor, order=0)\n",
    "        \n",
    "        # Append the scaled map to the list\n",
    "        scaled_maps_list.append(scaled_map)\n",
    "\n",
    "# Convert the list to a numpy array\n",
    "small_maps = np.array(scaled_maps_list)\n",
    "\n",
    "# Optionally save the small_maps array for later use\n",
    "np.save(\"scaled_occupancymaps_filtered.npy\", small_maps)\n",
    "\n",
    "# Check the shape to ensure the maps have been correctly resized and filtered\n",
    "print(small_maps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:06<00:00,  3.88it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.88it/s]\n"
     ]
    }
   ],
   "source": [
    "train_trial = 25\n",
    "test_trial = 4\n",
    "goal_trials = 1\n",
    "\n",
    "env_size = 80\n",
    "\n",
    "travel_time_values_array_train, signed_distance_array_train, velocity_matrices_array_train, goals_train = create_dataset(maps=maps[:train_trial,:,:,:], num_trials=train_trial, goal_trials=goal_trials, env_size=env_size,erosion_trials = 1)\n",
    "travel_time_values_array_test,  signed_distance_array_test,  velocity_matrices_array_test,  goals_test =  create_dataset(maps=maps[train_trial:,:,:,:], num_trials=test_trial,  goal_trials=goal_trials, env_size=env_size,erosion_trials = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14 sucks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pykonal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
