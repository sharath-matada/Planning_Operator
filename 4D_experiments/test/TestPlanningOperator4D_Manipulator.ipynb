{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as tvt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "from functools import reduce\n",
    "from functools import partial\n",
    "\n",
    "os.chdir(\"..\")\n",
    "\n",
    "from timeit import default_timer\n",
    "import scipy.io\n",
    "import sys\n",
    "from itertools import chain\n",
    "import skfmm\n",
    "import time\n",
    "\n",
    "from models.TrainPlanningOperator4D import PlanningOperator4D, smooth_chi\n",
    "from models.utilities import *\n",
    "from scipy.io import loadmat\n",
    "from planner import getPNOValueFunction, perform_gradient_descent, generaterandompos, getFMMValueFunction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the Trained Model and Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PlanningOperator4D(\n",
       "  (fc0): Linear(in_features=4, out_features=7, bias=True)\n",
       "  (conv0): SpectralConv4d()\n",
       "  (w0): Conv4d(\n",
       "    (conv3d_layers): ModuleList(\n",
       "      (0): Conv3d(7, 7, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (fc1): DeepNormMetric(\n",
       "    (Us): ModuleList(\n",
       "      (0-1): 2 x Linear(in_features=7, out_features=128, bias=False)\n",
       "    )\n",
       "    (Ws): ModuleList(\n",
       "      (0): ConstrainedLinear(in_features=128, out_features=128, bias=False)\n",
       "    )\n",
       "    (activation): MaxReLUPairwiseActivation(\n",
       "      (avg_pool): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "    )\n",
       "    (output_activation): ConcaveActivation()\n",
       "    (reduce_metric): ReduceMetric()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maps = loadmat('dataset/occupancyGridsSphere_matlab.mat') \n",
    "occupancygrids = 1 - maps['occupancyGrids']\n",
    "obstaclepositions = maps['blockPositions']\n",
    "testmaps = occupancygrids#Unseen Maps\n",
    "testobstaclepositions = obstaclepositions\n",
    "goalpos = generaterandompos(testmaps)\n",
    "startpos = generaterandompos(testmaps)\n",
    "\n",
    "modes = 3\n",
    "width = 7\n",
    "nlayers = 1\n",
    "\n",
    "model = PlanningOperator4D(modes, modes, modes, modes, width, nlayers)\n",
    "model.load_state_dict(torch.load(\"dataset/manipulator/planningoperator_manipulator17_m3_w8_l1_b10_lr3e-3_10g_20nov/n400_lr1.000000e-02_gamma6.000000e-01_wd3.000000e-06_seed5/model4d.ckpt\"))\n",
    "model.eval()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cfg_trajectory(path, num_divisions=17):\n",
    "    \"\"\"Convert a path array to a cfg_trajectory dictionary.\"\"\"\n",
    "    \n",
    "    # Generate joint range (-π to π) divided into num_divisions\n",
    "    joint_range = np.linspace(-np.pi, np.pi, num_divisions)\n",
    "\n",
    "    # Initialize trajectory dictionary for the 4 DOF joints\n",
    "    cfg_trajectory = {\n",
    "        'joint1': [],\n",
    "        'joint2': [],\n",
    "        'joint3': [],\n",
    "        'joint4': []\n",
    "    }\n",
    "\n",
    "    # Map indices to joint angles and populate the cfg_trajectory dictionary\n",
    "    for state in path:\n",
    "        cfg_trajectory['joint1'].append(joint_range[int(state[0])])\n",
    "        cfg_trajectory['joint2'].append(joint_range[int(state[1])])\n",
    "        cfg_trajectory['joint3'].append(joint_range[int(state[2])])\n",
    "        cfg_trajectory['joint4'].append(joint_range[int(state[3])])\n",
    "\n",
    "    return cfg_trajectory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Value Function and Generate Trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.12705108  0.11793257  0.05772725]\n",
      " [-0.04855625  0.12463218  0.01313024]]\n",
      "Success: True Path Length: 12.292528739883945\n"
     ]
    }
   ],
   "source": [
    "test_idx = 14\n",
    "test_idx = test_idx - 1\n",
    "\n",
    "teststart = np.array([0, 3, 5, 8])\n",
    "testgoal = np.array([8, 3, 5, 8])\n",
    "\n",
    "testmap = testmaps[test_idx,:,:,:,:].squeeze()\n",
    "testobstaclepositions = obstaclepositions[test_idx,:,:]\n",
    "valuefunction =  getPNOValueFunction(testmap, testgoal, model)\n",
    "print(testobstaclepositions)\n",
    "success, path_length, path = perform_gradient_descent(valuefunction, teststart, testgoal)\n",
    "print(\"Success:\",success, \"Path Length:\", path_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path_urdfpy = np.array(path)\n",
    "from urdfpy import URDF, Link, Joint, Visual, Collision, Geometry, Sphere, Material\n",
    "from urdfpy import xyz_rpy_to_matrix\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "\n",
    "# Load the original robot URDF\n",
    "robot = URDF.load('robot/open_manipulator/open_manipulator_x_description/urdf/open_manipulator_x_robot.urdf')\n",
    "\n",
    "# Scaling factor used in MATLAB\n",
    "urdfpy_scaling = 2.0\n",
    "\n",
    "# Define obstacle positions and radii\n",
    "obstacle_positions = [\n",
    "    [testobstaclepositions[0,0]/urdfpy_scaling, testobstaclepositions[0,1]/urdfpy_scaling, testobstaclepositions[0,2]/urdfpy_scaling],   # (x, y, z)\n",
    "    [testobstaclepositions[1,0]/urdfpy_scaling, testobstaclepositions[1,1]/urdfpy_scaling, testobstaclepositions[1,2]/urdfpy_scaling]\n",
    "]\n",
    "obstacle_radii = [0.08, 0.08]  # Radii of spheres\n",
    "\n",
    "# Define obstacle colors (RGBA)\n",
    "obstacle_colors = [\n",
    "    [1.0, 0.0, 0.0, 1.0],  # Red\n",
    "    [0.0, 0.0, 1.0, 1.0]   # Blue\n",
    "]\n",
    "\n",
    "obstacle_links = []\n",
    "obstacle_joints = []\n",
    "\n",
    "base_link = \"world\"\n",
    "\n",
    "# Create obstacle links and joints\n",
    "for i, (pos, radius) in enumerate(zip(obstacle_positions, obstacle_radii)):\n",
    "    sphere_geom = Geometry(sphere=Sphere(radius=radius))\n",
    "    origin = pos + [0, 0, 0]  # No rotation\n",
    "\n",
    "    material = Material(name=f\"obstacle_color_{i}\", color=obstacle_colors[i])\n",
    "    visual = Visual(name=f\"obstacle_{i}_visual\", geometry=sphere_geom, origin=origin, material=material)\n",
    "    collision = Collision(name=f\"obstacle_{i}_collision\", geometry=sphere_geom, origin=origin)\n",
    "\n",
    "    obstacle_link = Link(name=f\"obstacle_{i}\", inertial=None, visuals=[visual], collisions=[collision])\n",
    "    obstacle_joint = Joint(\n",
    "        name=f\"obstacle_{i}_joint\",\n",
    "        joint_type=\"fixed\",\n",
    "        parent=base_link,\n",
    "        child=obstacle_link.name,\n",
    "        origin=origin\n",
    "    )\n",
    "\n",
    "    obstacle_links.append(obstacle_link)\n",
    "    obstacle_joints.append(obstacle_joint)\n",
    "\n",
    "# Define manipulator material color (green)\n",
    "manipulator_material = Material(name=\"manipulator_color\", color=[0.2, 0.8, 0.2, 1.0])\n",
    "\n",
    "# Rebuild each link with new visual materials\n",
    "colored_links = []\n",
    "for link in robot.links:\n",
    "    new_visuals = []\n",
    "    for visual in link.visuals:\n",
    "        new_visual = Visual(\n",
    "            geometry=visual.geometry,\n",
    "            origin=visual.origin,\n",
    "            material=manipulator_material\n",
    "        )\n",
    "        new_visuals.append(new_visual)\n",
    "\n",
    "    # Reconstruct the link with updated visuals\n",
    "    colored_link = Link(\n",
    "        name=link.name,\n",
    "        inertial=link.inertial,\n",
    "        visuals=new_visuals,\n",
    "        collisions=link.collisions\n",
    "    )\n",
    "    colored_links.append(colored_link)\n",
    "\n",
    "# Construct the new URDF\n",
    "new_urdf = URDF(\n",
    "    name=\"robot_with_colored_obstacles\",\n",
    "    links=colored_links + obstacle_links,\n",
    "    joints=robot.joints + obstacle_joints\n",
    ")\n",
    "\n",
    "# Generate your trajectory here\n",
    "# Make sure the `generate_cfg_trajectory(path)` function is defined elsewhere\n",
    "cfg_trajectory = generate_cfg_trajectory(path_urdfpy)\n",
    "\n",
    "# Animate the URDF\n",
    "new_urdf.animate(cfg_trajectory=cfg_trajectory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old stuff"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuraloperator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
